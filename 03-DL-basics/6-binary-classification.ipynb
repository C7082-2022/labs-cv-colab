{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91fdee1b-6840-4366-8f2a-9b854858d332",
   "metadata": {},
   "source": [
    "# Lab 06 Binary classification\n",
    "\n",
    "<br>\n",
    "\n",
    "<center>\n",
    "    \n",
    "<img src=\"img/craiyon-binary.jpg\" alt=\"Spam\" width=\"300\"/> \n",
    "    \n",
    "    Craiyon.com \"Binary classification\" \n",
    "    \n",
    "</center>    \n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e2923b-a875-47c2-ab4d-84a2c3ff716f",
   "metadata": {},
   "source": [
    "## 1 Objectives\n",
    "\n",
    "So far, we've learned about how neural networks can solve regression problems. \n",
    "\n",
    "Now we're going to \n",
    "- apply neural networks to classification\n",
    "- evaluate difference for the loss function\n",
    "- practice classification outputs for the final layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c5cceb-59d9-429f-aede-5de1a3af1fa6",
   "metadata": {},
   "source": [
    "## 2 Binary Classification #\n",
    "\n",
    "Classification into one of two classes is a common machine learning problem. You might want to predict whether or not a customer is likely to make a purchase, whether or not a credit card transaction was fraudulent, whether deep space signals show evidence of a new planet, or a medical test evidence of a disease. These are all **binary classification** problems.\n",
    "\n",
    "In your raw data, the classes might be represented by strings like `\"Yes\"` and `\"No\"`, or `\"Dog\"` and `\"Cat\"`. Before using this data we'll assign a **class label**: one class will be `0` and the other will be `1`. Assigning numeric labels puts the data in a form a neural network can use.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ade5b01-73e2-4a67-8f48-f488c96c2907",
   "metadata": {},
   "source": [
    "## 3 Accuracy and Cross-Entropy\n",
    "\n",
    "**Accuracy** is one of the many metrics in use for measuring success on a classification problem. Accuracy is the ratio of correct predictions to total predictions: `accuracy = number_correct / total`. A model that always predicted correctly would have an accuracy score of `1.0`. All else being equal, accuracy is a reasonable metric to use whenever the classes in the dataset occur with about the same frequency.\n",
    "\n",
    "The problem with accuracy (and most other classification metrics) is that it can't be used as a loss function. SGD needs a loss function that changes smoothly, but accuracy, being a ratio of counts, changes in \"jumps\". So, we have to choose a substitute to act as the loss function. This substitute is the *cross-entropy* function.\n",
    "\n",
    "Now, recall that the loss function defines the *objective* of the network during training. With regression, our goal was to minimize the distance between the expected outcome and the predicted outcome. We chose MAE to measure this distance.\n",
    "\n",
    "For classification, what we want instead is a distance between *probabilities*, and this is what cross-entropy provides. **Cross-entropy** is a sort of measure for the distance from one probability distribution to another.\n",
    "\n",
    "<center>\n",
    "<figure style=\"padding: 1em;\">\n",
    "<img src=\"img\\6-1.png\" width=\"400\" alt=\"Graphs of accuracy and cross-entropy.\">\n",
    "<figcaption style=\"textalign: center; font-style: italic\">Cross-entropy penalizes incorrect probability predictions.</figcaption>\n",
    "</figure>\n",
    "</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "The idea is that we want our network to predict the correct class with probability `1.0`. The further away the predicted probability is from `1.0`, the greater will be the cross-entropy loss.\n",
    "\n",
    "The technical reasons we use cross-entropy are a bit subtle, but the main thing to take away from this section is just this: use cross-entropy for a classification loss; other metrics you might care about (like accuracy) will tend to improve along with it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03a60d1",
   "metadata": {
    "papermill": {
     "duration": 0.012641,
     "end_time": "2022-05-05T17:51:37.673131",
     "exception": false,
     "start_time": "2022-05-05T17:51:37.660490",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "## 4 Making Probabilities with the Sigmoid Function\n",
    "\n",
    "The cross-entropy and accuracy functions both require probabilities as inputs, meaning, numbers from 0 to 1. To covert the real-valued outputs produced by a dense layer into probabilities, we attach a new kind of activation function, the **sigmoid activation**.\n",
    "\n",
    "<center>\n",
    "<figure style=\"padding: 1em;\">\n",
    "<img src=\"img\\6-2.png\" width=\"400\" alt=\"The sigmoid graph is an 'S' shape with horizontal asymptotes at 0 to the left and 1 to the right. \">\n",
    "<figcaption style=\"textalign: center; font-style: italic\">The sigmoid function maps real numbers into the interval $[0, 1]$.</figcaption>\n",
    "</figure>\n",
    "</center>\n",
    "\n",
    "To get the final class prediction, we define a *threshold* probability. Typically this will be 0.5, so that rounding will give us the correct class: below 0.5 means the class with label 0 and 0.5 or above means the class with label 1. A 0.5 threshold is what Keras uses by default with its [accuracy metric](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/BinaryAccuracy).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857c702a-8368-42fc-9225-d8137cca9b69",
   "metadata": {},
   "source": [
    "## 5 Example - Binary Classification\n",
    "\n",
    "Now let's try it out!\n",
    "\n",
    "The [Ionosphere](https://archive.ics.uci.edu/ml/datasets/Ionosphere) dataset contains features obtained from radar signals focused on the ionosphere layer of the Earth's atmosphere. The task is to determine whether the signal shows the presence of some object, or just empty air."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41f4564e",
   "metadata": {
    "_kg_hide-input": true,
    "lines_to_next_cell": 0,
    "papermill": {
     "duration": 0.117612,
     "end_time": "2022-05-05T17:51:37.802143",
     "exception": false,
     "start_time": "2022-05-05T17:51:37.684531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>V29</th>\n",
       "      <th>V30</th>\n",
       "      <th>V31</th>\n",
       "      <th>V32</th>\n",
       "      <th>V33</th>\n",
       "      <th>V34</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   V1  V2       V3       V4       V5       V6       V7       V8       V9  \\\n",
       "1   1   0  0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708  1.00000   \n",
       "2   1   0  1.00000 -0.18829  0.93035 -0.36156 -0.10868 -0.93597  1.00000   \n",
       "3   1   0  1.00000 -0.03365  1.00000  0.00485  1.00000 -0.12062  0.88965   \n",
       "4   1   0  1.00000 -0.45161  1.00000  1.00000  0.71216 -1.00000  0.00000   \n",
       "5   1   0  1.00000 -0.02401  0.94140  0.06531  0.92106 -0.23255  0.77152   \n",
       "\n",
       "       V10  ...      V26      V27      V28      V29      V30      V31  \\\n",
       "1  0.03760  ... -0.51171  0.41078 -0.46168  0.21266 -0.34090  0.42267   \n",
       "2 -0.04549  ... -0.26569 -0.20468 -0.18401 -0.19040 -0.11593 -0.16626   \n",
       "3  0.01198  ... -0.40220  0.58984 -0.22145  0.43100 -0.17365  0.60436   \n",
       "4  0.00000  ...  0.90695  0.51613  1.00000  1.00000 -0.20099  0.25682   \n",
       "5 -0.16399  ... -0.65158  0.13290 -0.53206  0.02431 -0.62197 -0.05707   \n",
       "\n",
       "       V32      V33      V34  Class  \n",
       "1 -0.54487  0.18641 -0.45300   good  \n",
       "2 -0.06288 -0.13738 -0.02447    bad  \n",
       "3 -0.24180  0.56045 -0.38238   good  \n",
       "4  1.00000 -0.32382  1.00000    bad  \n",
       "5 -0.59573 -0.04608 -0.65697   good  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "ion = pd.read_csv('data/ion.csv', index_col=0)\n",
    "display(ion.head())\n",
    "\n",
    "df = ion.copy()\n",
    "df['Class'] = df['Class'].map({'good': 0, 'bad': 1})\n",
    "\n",
    "df_train = df.sample(frac=0.7, random_state=0)\n",
    "df_valid = df.drop(df_train.index)\n",
    "\n",
    "max_ = df_train.max(axis=0)\n",
    "min_ = df_train.min(axis=0)\n",
    "\n",
    "df_train = (df_train - min_) / (max_ - min_)\n",
    "df_valid = (df_valid - min_) / (max_ - min_)\n",
    "df_train.dropna(axis=1, inplace=True) # drop the empty feature in column 2\n",
    "df_valid.dropna(axis=1, inplace=True)\n",
    "\n",
    "X_train = df_train.drop('Class', axis=1)\n",
    "X_valid = df_valid.drop('Class', axis=1)\n",
    "y_train = df_train['Class']\n",
    "y_valid = df_valid['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68c5021",
   "metadata": {
    "papermill": {
     "duration": 0.010477,
     "end_time": "2022-05-05T17:51:37.824025",
     "exception": false,
     "start_time": "2022-05-05T17:51:37.813548",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<br>\n",
    "\n",
    "We'll define our model just like we did for the regression tasks, with one exception. In the final layer include a `'sigmoid'` activation so that the model will produce class probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6fde980",
   "metadata": {
    "papermill": {
     "duration": 6.43411,
     "end_time": "2022-05-05T17:51:44.268949",
     "exception": false,
     "start_time": "2022-05-05T17:51:37.834839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(4, activation='relu', input_shape=[33]),\n",
    "    layers.Dense(4, activation='relu'),    \n",
    "    layers.Dense(1, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6589ad9c",
   "metadata": {
    "papermill": {
     "duration": 0.011413,
     "end_time": "2022-05-05T17:51:44.292372",
     "exception": false,
     "start_time": "2022-05-05T17:51:44.280959",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<br>\n",
    "\n",
    "Add the cross-entropy loss and accuracy metric to the model with its `compile` method. For two-class problems, be sure to use `'binary'` versions. (Problems with more classes will be slightly different.) The Adam optimizer works great for classification too, so we'll stick with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e21df474",
   "metadata": {
    "papermill": {
     "duration": 0.027298,
     "end_time": "2022-05-05T17:51:44.331864",
     "exception": false,
     "start_time": "2022-05-05T17:51:44.304566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['binary_accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3557739",
   "metadata": {
    "papermill": {
     "duration": 0.011413,
     "end_time": "2022-05-05T17:51:44.354965",
     "exception": false,
     "start_time": "2022-05-05T17:51:44.343552",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<br>\n",
    "\n",
    "The model in this particular problem can take quite a few epochs to complete training, so we'll include an early stopping callback for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c7c3083",
   "metadata": {
    "papermill": {
     "duration": 1.502202,
     "end_time": "2022-05-05T17:51:45.868789",
     "exception": false,
     "start_time": "2022-05-05T17:51:44.366587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    patience=10,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    batch_size=512,\n",
    "    epochs=1000,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=0, # hide the output because we have so many epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51553df",
   "metadata": {
    "papermill": {
     "duration": 0.012027,
     "end_time": "2022-05-05T17:51:45.893150",
     "exception": false,
     "start_time": "2022-05-05T17:51:45.881123",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<br>\n",
    "\n",
    "We'll take a look at the learning curves as always, and also inspect the best values for the loss and accuracy we got on the validation set. (Remember that early stopping will restore the weights to those that got these values.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31915ecd",
   "metadata": {
    "papermill": {
     "duration": 0.441151,
     "end_time": "2022-05-05T17:51:46.346481",
     "exception": false,
     "start_time": "2022-05-05T17:51:45.905330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# might need colab\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "# Start the plot at epoch 5\n",
    "history_df.loc[5:, ['loss', 'val_loss']].plot()\n",
    "history_df.loc[5:, ['binary_accuracy', 'val_binary_accuracy']].plot()\n",
    "\n",
    "print((\"Best Validation Loss: {:0.4f}\" +\\\n",
    "      \"\\nBest Validation Accuracy: {:0.4f}\")\\\n",
    "      .format(history_df['val_loss'].min(), \n",
    "              history_df['val_binary_accuracy'].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cc173a-efbf-4004-a5fd-06b3bd08b59f",
   "metadata": {},
   "source": [
    "## 6 Ecercises\n",
    "\n",
    "Here, you'll build a model to predict hotel cancellations with a binary classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b462e756-5d48-4550-adbe-fb416d8ff481",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Setup plotting\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "# Set Matplotlib defaults\n",
    "plt.rc('figure', autolayout=True)\n",
    "plt.rc('axes', labelweight='bold', labelsize='large',\n",
    "       titleweight='bold', titlesize=18, titlepad=10)\n",
    "plt.rc('animation', html='html5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e029662d-f1b4-4a79-986f-21f584dae214",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "First, load the *Hotel Cancellations* dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdb5a6ef-96a0-419b-bba8-2fd604c1c2c7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "hotel = pd.read_csv('data/hotel.csv')\n",
    "\n",
    "X = hotel.copy()\n",
    "y = X.pop('is_canceled')\n",
    "\n",
    "X['arrival_date_month'] = \\\n",
    "    X['arrival_date_month'].map(\n",
    "        {'January':1, 'February': 2, 'March':3,\n",
    "         'April':4, 'May':5, 'June':6, 'July':7,\n",
    "         'August':8, 'September':9, 'October':10,\n",
    "         'November':11, 'December':12}\n",
    "    )\n",
    "\n",
    "features_num = [\n",
    "    \"lead_time\", \"arrival_date_week_number\",\n",
    "    \"arrival_date_day_of_month\", \"stays_in_weekend_nights\",\n",
    "    \"stays_in_week_nights\", \"adults\", \"children\", \"babies\",\n",
    "    \"is_repeated_guest\", \"previous_cancellations\",\n",
    "    \"previous_bookings_not_canceled\", \"required_car_parking_spaces\",\n",
    "    \"total_of_special_requests\", \"adr\",\n",
    "]\n",
    "features_cat = [\n",
    "    \"hotel\", \"arrival_date_month\", \"meal\",\n",
    "    \"market_segment\", \"distribution_channel\",\n",
    "    \"reserved_room_type\", \"deposit_type\", \"customer_type\",\n",
    "]\n",
    "\n",
    "transformer_num = make_pipeline(\n",
    "    SimpleImputer(strategy=\"constant\"), # there are a few missing values\n",
    "    StandardScaler(),\n",
    ")\n",
    "transformer_cat = make_pipeline(\n",
    "    SimpleImputer(strategy=\"constant\", fill_value=\"NA\"),\n",
    "    OneHotEncoder(handle_unknown='ignore'),\n",
    ")\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (transformer_num, features_num),\n",
    "    (transformer_cat, features_cat),\n",
    ")\n",
    "\n",
    "# stratify - make sure classes are evenlly represented across splits\n",
    "X_train, X_valid, y_train, y_valid = \\\n",
    "    train_test_split(X, y, stratify=y, train_size=0.75)\n",
    "\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_valid = preprocessor.transform(X_valid)\n",
    "\n",
    "input_shape = [X_train.shape[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa922eb1-9dfc-41c6-a39d-711870639006",
   "metadata": {},
   "source": [
    "### 6.1 Define Model\n",
    "\n",
    "The model we'll use this time will have both batch normalization and dropout layers. To ease reading we've broken the diagram into blocks, but you can define it layer by layer as usual.\n",
    "\n",
    "Define a model with an architecture given by this diagram:\n",
    "\n",
    "<center>\n",
    "<figure style=\"padding: 1em;\">\n",
    "<img src=\"img\\6-3.png\" width=\"400\" alt=\"Diagram of network architecture: BatchNorm, Dense, BatchNorm, Dropout, Dense, BatchNorm, Dropout, Dense.\">\n",
    "<figcaption style=\"textalign: center; font-style: italic\">Diagram of a binary classifier.</figcaption>\n",
    "</figure>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d3c3939-5c6d-4e96-a7bd-d018e98abcc2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# YOUR CODE HERE: define the model given in the diagram\n",
    "# model = ____\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0f8c86-1964-4da4-8cee-809f838239e5",
   "metadata": {},
   "source": [
    "### 6.2 Add Optimizer, Loss, and Metric\n",
    "\n",
    "Now compile the model with the Adam optimizer and binary versions of the cross-entropy loss and accuracy metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f40b42-3a01-426a-8c18-7595ef7a54c8",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# ____\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9a4fa4-2982-45b1-93b2-3de55acc215d",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Finally, run this cell to train the model and view the learning curves. It may run for around 60 to 70 epochs, which could take a minute or two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ad39b4-ce3c-46aa-8034-c814b1d65707",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    patience=5,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    batch_size=512,\n",
    "    epochs=200,\n",
    "    callbacks=[early_stopping],\n",
    ")\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.loc[:, ['loss', 'val_loss']].plot(title=\"Cross-entropy\")\n",
    "history_df.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot(title=\"Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b14937-487b-4a61-9924-10af06024b11",
   "metadata": {},
   "source": [
    "### 6.3 Train and Evaluate \n",
    "\n",
    "\n",
    "What do you think about the learning curves? Does it look like the model underfit or overfit? Was the cross-entropy loss a good stand-in for accuracy?"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 21.577474,
   "end_time": "2022-05-05T17:51:49.407928",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-05T17:51:27.830454",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
